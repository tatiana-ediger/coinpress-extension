{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pleasant-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import algos\n",
    "import lin_reg_algos\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spanish-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linreg(x, y, beta, c, r, total_budget):\n",
    "    \"\"\"\n",
    "    input:\n",
    "    output:\n",
    "    beta_hat = mean_est @ np.inv(cov_est)\n",
    "    \"\"\"\n",
    "    n = len(x)\n",
    "    d = len(x[0])\n",
    "\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(x[i] * y[i])\n",
    "    z = np.array(z)\n",
    "\n",
    "    # TODO: private beta_norm_sqr !!\n",
    "    beta_norm_sqr = beta_l2_norm(y, d) #np.linalg.norm(beta) ** 2\n",
    "\n",
    "    mean_est = coinpress_linreg_mean(z, c, r, d, beta_norm_sqr, total_budget)\n",
    "    cov_est = coinpress_linalg_covariance(x, d, 2, total_budget)\n",
    "    beta_hat = mean_est @ np.linalg.inv(cov_est)\n",
    "    return beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "determined-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beta_l2_norm(y, d, t=2, total_budget=0.1):\n",
    "    '''need y and args={d, u, rho, t}'''\n",
    "    y = torch.FloatTensor(y)\n",
    "\n",
    "    class Args:\n",
    "        def __init__(self, n, d, u, rho, t):\n",
    "            self.n = n\n",
    "            self.d = d\n",
    "            self.u = u\n",
    "            self.rho = rho\n",
    "            self.t = t\n",
    "\n",
    "    n = len(y)\n",
    "    rho = [(1.0 / 4.0) * total_budget, (3.0 / 4.0) * total_budget]\n",
    "    u = 100 * d\n",
    "    args = Args(n, d, u, rho, t)\n",
    "    return algos.cov_est(y, args) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intense-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_cov_est_priv_linreg(x, y, beta, c, r, total_budget):\n",
    "    '''multiplies by (1/n)*np.linalg.inv(X.T@X) instead of inverse of covariance estimation'''\n",
    "    \n",
    "    n = len(x)\n",
    "    d = len(x[0])\n",
    "\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(x[i] * y[i])\n",
    "    z = np.array(z)\n",
    "\n",
    "    # TODO: private beta_norm_sqr !!\n",
    "    beta_norm_sqr = np.linalg.norm(beta) ** 2\n",
    "\n",
    "    mean_est = coinpress_linreg_mean(z, c, r, d, beta_norm_sqr, total_budget)\n",
    "    beta_hat = mean_est @ np.linalg.inv((1/n)*x.T@x)\n",
    "    return beta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "several-humanitarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linalg_covariance(x, d, t=2, total_budget=0.5):\n",
    "    '''need X and args={d, u, rho, t}'''\n",
    "    x = torch.FloatTensor(x)\n",
    "    \n",
    "    class Args:\n",
    "        def __init__(self, n, d, u, rho, t):\n",
    "            self.n = n\n",
    "            self.d = d\n",
    "            self.u = u\n",
    "            self.rho = rho\n",
    "            self.t = t\n",
    "\n",
    "    n = len(x)\n",
    "    rho = [(1.0 / 4.0) * total_budget, (3.0 / 4.0) * total_budget]\n",
    "    # u = upper bound on largest eigenvalue on true covariance matrix\n",
    "    u = 10 * np.sqrt(d)\n",
    "    args = Args(n, d, u, rho, t)\n",
    "    return algos.cov_est(x, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rotary-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linreg_mean(z, c, r, d, beta_norm_sqr, total_budget=0.5):\n",
    "    z = z / np.sqrt(2 * beta_norm_sqr + 1)\n",
    "    rho = [(1.0 / 4.0) * total_budget, (3.0 / 4.0) * total_budget]\n",
    "    return algos.multivariate_mean_iterative(z, c, r, 2, rho) * np.sqrt(2 * beta_norm_sqr + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "desirable-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses(n_values, d, iters, total_privacy_budget, loss_func, beta_mean=0, beta_var=1.0):\n",
    "    \"\"\"\n",
    "    returns excess loss of the private, coinpress linear regression solution\n",
    "    and excess loss for the closed form solution of linear regression.\n",
    "\n",
    "    where excess loss = E[(<x,beta_hat> - y)**2 - (<x,beta> - y)**2]\n",
    "    \"\"\"\n",
    "\n",
    "    no_cov_est_priv_losses = []\n",
    "    nonpriv_losses = []\n",
    "    priv_losses = []\n",
    "    coinpress_nonpriv_losses = []\n",
    "\n",
    "    for n in n_values:\n",
    "        no_cov_est_priv_losses_for_n = []\n",
    "        nonpriv_losses_for_n = []\n",
    "        priv_losses_for_n = []\n",
    "        conpress_nonpriv_losses_for_n = []\n",
    "\n",
    "        for i in range(iters):\n",
    "            c = [0] * d\n",
    "            r = 100 * np.sqrt(d)\n",
    "\n",
    "            underlying_dist = generate_normal_underlying_dist(d, beta_mean, beta_var)\n",
    "            x, y, _ = generate_data(n, d, underlying_dist)\n",
    "\n",
    "            \"\"\" in each iteration, running the estimation to find beta_hat for each of the following scenarios \"\"\"\n",
    "            no_cov_est_priv_beta_hat = no_cov_est_priv_linreg(x, y, underlying_dist, c, r, total_privacy_budget)\n",
    "            no_cov_est_priv_losses_for_n.append(loss_func(no_cov_est_priv_beta_hat, underlying_dist[0], d))\n",
    "            \n",
    "            priv_beta_hat = lin_reg_algos.coinpress_linreg(x, y, underlying_dist, c, r, total_privacy_budget)\n",
    "            priv_losses_for_n.append(loss_func(priv_beta_hat, underlying_dist[0], d))\n",
    "\n",
    "            nonpriv_beta_hat = linreg_closed_form_solution(x, y)\n",
    "            nonpriv_losses_for_n.append(loss_func(nonpriv_beta_hat, underlying_dist[0], d))\n",
    "            \n",
    "            coinpress_nonpriv_beta_hat = lin_reg_algos.coinpress_linreg(x, y, underlying_dist, c, r, 1000)\n",
    "            conpress_nonpriv_losses_for_n.append(loss_func(coinpress_nonpriv_beta_hat, underlying_dist[0], d))\n",
    "            \n",
    "#             coinpress_r10000_beta_hat = lin_reg_algos.coinpress_linreg(x, y, underlying_dist, c, r*100, total_privacy_budget)\n",
    "#             coinpress_r10000_losses_for_n.append(loss_func())\n",
    "\n",
    "        \"\"\" finds the mean loss for the current n for each of the following scenarios \"\"\"\n",
    "        no_cov_est_losses_for_n = np.array(no_cov_est_priv_losses_for_n)\n",
    "        no_cov_est_priv_losses.append(np.mean(no_cov_est_priv_losses_for_n))\n",
    "        \n",
    "        priv_losses_for_n = np.array(priv_losses_for_n)\n",
    "        priv_losses.append(np.mean(priv_losses_for_n))\n",
    "        \n",
    "        nonpriv_losses_for_n = np.array(nonpriv_losses_for_n)\n",
    "        nonpriv_losses.append(np.mean(nonpriv_losses_for_n))\n",
    "        \n",
    "        conpress_nonpriv_losses_for_n = np.array(conpress_nonpriv_losses_for_n)\n",
    "        coinpress_nonpriv_losses.append(np.mean(conpress_nonpriv_losses_for_n))\n",
    "        \n",
    "    # TODO : add title, make y axis 0 -> 2, make sure label in top right corner / out of the way!\n",
    "    plt.plot(n_values, priv_losses, 'b', label='losses using algorithm')\n",
    "    plt.plot(n_values, nonpriv_losses, 'r', label='losses using closed form sol')\n",
    "    plt.plot(n_values, no_cov_est_priv_losses, 'y', label='losses using algo w/o cov est.')\n",
    "    plt.plot(n_values, coinpress_nonpriv_losses, 'g', label='losses using coinpress nonprivately')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0,5])\n",
    "\n",
    "    return priv_losses, nonpriv_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automated-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_normal_underlying_dist(d, beta_mean, beta_var):\n",
    "    \"\"\" generates beta, <X,beta> = y\"\"\"\n",
    "    underlying_dist = np.random.normal(beta_mean, beta_var, (1, d))\n",
    "    return np.array(underlying_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "closed-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n, d, underlying_dist):\n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "\n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = np.random.normal(0, 1.0, (n, d))\n",
    "    X = np.array(X)\n",
    "\n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + np.random.normal(0, 1))\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "\n",
    "    return X, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "separate-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg_closed_form_solution(x, y):\n",
    "    return np.linalg.inv(x.T @ x) @ x.T @ y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nuclear-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "def excess_loss(beta_hat, beta, d):\n",
    "    \"\"\"\n",
    "    Generate 1000 d-dimensional x values and y values to test excess loss\n",
    "    of our predicted beta_hat vs. underlying distribution beta\n",
    "    \"\"\"\n",
    "\n",
    "    n = 1000\n",
    "    x = np.random.normal(0, 1.0, (n, d))\n",
    "    x = np.array(x)\n",
    "    y = []\n",
    "\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(beta, x[i]) + np.random.normal(0, 1.0))\n",
    "    y = np.array(y)\n",
    "\n",
    "    sum_losses = 0\n",
    "    for i in range(n):\n",
    "        predicted_dist = (x[i] @ beta_hat - y[i]) ** 2\n",
    "        actual_dist = (x[i] @ beta - y[i]) ** 2  # if this = 1, it's essentially the same thing as n -> \\inf\n",
    "        loss = predicted_dist - actual_dist\n",
    "        sum_losses += loss\n",
    "    return sum_losses / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "environmental-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_loss(beta_hat, beta, d):\n",
    "    \n",
    "    # make trimmed mean? throw out 5 most extreme values?\n",
    "    \n",
    "    n = 1000\n",
    "    \n",
    "    '''generate new x values'''\n",
    "    x = np.random.normal(0, 1.0, (n, d))\n",
    "    x = np.array(x)\n",
    "    y = []\n",
    "\n",
    "    '''generate new y values based on underlying distribution, beta'''\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(beta, x[i]) + np.random.normal(0, 1.0))\n",
    "    y = np.array(y)\n",
    "    \n",
    "    '''find squared accuracy of prediction for each entry of x'''\n",
    "    def dist(xi,yi):\n",
    "        return np.clip((xi @ beta_hat - yi) ** 2, -5, 5)\n",
    "    \n",
    "    '''return MSE?'''\n",
    "    losses = list(map(dist, x, y))\n",
    "    # clip mean ? throw out really high values instead of trimming mean (throw out values bigger than 5)\n",
    "    return np.mean(np.array(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "regulated-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9276776055813232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" WHY IS THIS sometimes less than 1?\"\"\"\n",
    "\n",
    "pop_loss([1,2,2],[1,2,2],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "separate-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_error(beta_hat, beta, d):\n",
    "    return np.linalg.norm((beta_hat-beta), ord=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "framed-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_error(beta_hat, beta, d):\n",
    "    return np.linalg.norm(np.clip(beta_hat-beta, -5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stopped-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l_inf_error(beta_hat, beta, d):\n",
    "    return np.linalg.norm((beta_hat-beta), ord=float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "polish-class",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_inf_error(np.array([5,5,10]), np.array([1,1,1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "exempt-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_values = list(range(100, 1500, 100))#[100,400,900,1000,1050,2000,2500,3000,3500,4000,6000]#,8000,10000]\n",
    "# d = 5\n",
    "# iters = 30\n",
    "# total_privacy_budget=0.5\n",
    "\n",
    "# losses(n_values, d, iters, total_privacy_budget, excess_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "rotary-supervisor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.9962740458243458,\n",
       "  1.9729484482135857,\n",
       "  1.365939964124298,\n",
       "  1.1430773802162595,\n",
       "  1.070821391219549,\n",
       "  1.028008994902393,\n",
       "  1.0021529465525345,\n",
       "  0.9924169552495542,\n",
       "  0.9906183469054614,\n",
       "  0.9781069210391032],\n",
       " [0.9612373014966408,\n",
       "  0.954353968963527,\n",
       "  0.9542213538484317,\n",
       "  0.9643918478574102,\n",
       "  0.9532150611467056,\n",
       "  0.97335259789802,\n",
       "  0.958084944684759,\n",
       "  0.9583489937375601,\n",
       "  0.9708684054144477,\n",
       "  0.9590103742744568])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD8CAYAAABekO4JAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvfklEQVR4nO3deXRU9fn48fdnZrKRhEVAQKFCeljEhCwQthgEq8iiLCoCRRYRAVFQVAr+bJVyaGsrCnVBClUWV8C6tMq+lcUFAgVBCKuxX5DKokICZJmZz++PezNMkplkApnMTfK8zrln7jZ3nrl38uQzn7n3uUprjRBCCOuyhToAIYQQpZNELYQQFieJWgghLE4StRBCWJwkaiGEsDhJ1EIIYXGOQFZSSmUB2YALcGqtOwQzKCGEEJcFlKhNPbTWZ4IWiRBCCJ+k60MIISxOBXJlolLqW+AnQAN/01rP97HOWGAsQHR0dPs2bdpUcKhCCFF97dy584zWuqGvZYEm6uu11ieUUtcCa4GJWuvN/tbv0KGDzsjIuOKAhRCiplFK7fT3+19AXR9a6xPm4yngI6BjxYUnhBCiNGUmaqVUtFIqtnAc6AnsC3ZgQgghDIGc9dEI+EgpVbj+u1rrVUGNSgghhEeZiVprfQxIrIRYhEUVFBRw/PhxcnNzQx2KEFVeZGQkTZs2JSwsLODnlOc8alFDHT9+nNjYWJo3b475zUoIcQW01pw9e5bjx4/TokWLgJ8n51GLMuXm5lK/fn1J0kJcJaUU9evXL/e3U0nUIiCSpIWoGFfytySJWgghLE4StagSYmJiQh1Cuc2bN48lS5YE9TVGjRrFBx98UCHbysjIYNKkSQBs2rSJzz//PCivI8pPfkwUIkjGjx8f6hAC5nQ66dChAx06GBfGbdq0iZiYGLp27RriyARIi1pUMVprpkyZQnx8PAkJCSxduhSAkydP0q1bN5KSkoiPj2fLli24XC5GjRrlWXf27NkAHD16lF69etG+fXvS09PJzMwEYPny5cTHx5OYmEi3bt1KvPamTZu48847PdOPPvooixYtAmDatGm0bduWdu3a8dRTTwEwffp0Zs2aBUD37t2ZOnUqHTt2pFWrVmzZsgWAixcvct9999G2bVsGDhxIp06d8FV+YcaMGaSmphIfH8/YsWPxVfphxYoVtGnThvbt2zNp0iRPrD/++CMDBgygXbt2dO7cma+//toT3/Dhw0lLS2P48OGe95eVlcW8efOYPXs2SUlJnlg3b95M165diYuL87SuN23axC233EL//v2Ji4tj2rRpvPPOO3Ts2JGEhASOHj1ansMr/JAWtSiXxx+H3bsrdptJSTBnTmDrfvjhh+zevZs9e/Zw5swZUlNT6datG++++y533HEHzzzzDC6Xi4sXL7J7925OnDjBvn3GhbQ///wzAGPHjmXevHm0bNmSr776igkTJrBhwwZmzJjB6tWruf766z3rBuLs2bN89NFHZGZmopTy+1yn08n27dtZsWIFv//971m3bh1z586lXr167N+/n3379pGUlOTzuY8++ijPPvssAMOHD+fTTz/lrrvu8izPzc1l3LhxbN68mRYtWjB06FDPsueee47k5GQ+/vhjNmzYwIgRI9htHsT9+/ezdetWoqKi2LRpEwDNmzdn/PjxxMTEeP7pvPHGG5w8eZKtW7eSmZlJv379uPfeewHYs2cPBw4c4JprriEuLo4xY8awfft2/vrXv/LKK68wJ9CDK/ySFrWoUrZu3crQoUOx2+00atSIW265hR07dpCamsrChQuZPn06e/fuJTY2lri4OI4dO8bEiRNZtWoVtWvXJicnh88//5xBgwaRlJTEuHHjOHnyJABpaWmMGjWKBQsW4HK5Ao6pTp06REZG8uCDD/Lhhx9Sq1Ytn+vdfffdALRv356srCzP+xkyZAgA8fHxtGvXzudzN27cSKdOnUhISGDDhg188803RZZnZmYSFxfnOTfXO1Fv3bqV4cOHA3Drrbdy9uxZzp8/D0C/fv2IiooK6H0OGDAAm81G27Zt+eGHHzzzU1NTadKkCREREfzyl7+kZ8+eACQkJHjep7g60qIW5WLVxlG3bt3YvHkzn332GaNGjeKJJ55gxIgR7Nmzh9WrVzNv3jyWLVvGnDlzqFu3rqdF6W3evHl89dVXfPbZZ7Rv356dO3dSv359z3KHw4Hb7fZMF54L63A42L59O+vXr+eDDz7g1VdfZcOGDSW2HxERAYDdbsfpdAb83nJzc5kwYQIZGRk0a9aM6dOnV9hVotHR0QGvWxg/UKTrxXu+zWbzTNtstnK9T+GftKhFlZKens7SpUtxuVycPn2azZs307FjR7777jsaNWrEQw89xJgxY9i1axdnzpzB7XZzzz33MHPmTHbt2kXt2rVp0aIFy5cvB4yEs2fPHsDou+7UqRMzZsygYcOG/N///V+R177hhhvYv38/eXl5/Pzzz6xfvx6AnJwczp07R58+fZg9e7Zne4FIS0tj2bJlgNENsXfv3hLrFCblBg0akJOT4/Psi9atW3Ps2DFPC7aw775wn73zzjuA0afcoEEDateuXWpcsbGxZGdnB/w+RHBJi1pUKQMHDuSLL74gMTERpRR/+ctfaNy4MYsXL+aFF14gLCyMmJgYlixZwokTJ3jggQc8reA//elPALzzzjs8/PDDzJw5k4KCAoYMGUJiYiJTpkzh8OHDaK351a9+RWJi0RI3zZo147777iM+Pp4WLVqQnJwMQHZ2Nv379yc3NxetNS+99FLA72fChAmMHDmStm3b0qZNG2666Sbq1KlTZJ26devy0EMPER8fT+PGjUlNTS2xnaioKObOnUuvXr2Ijo4uss706dMZPXo07dq1o1atWixevLjMuO666y7uvfdePvnkE1555ZWA348IjoBuHFBecuOA6uXAgQPceOONoQ6jWnK5XBQUFBAZGcnRo0e57bbbOHjwIOHh4eXeVk5ODjExMWiteeSRR2jZsiWTJ08OQtTiavn6myrtxgHSohYihC5evEiPHj0oKChAa83cuXOvKEkDLFiwgMWLF5Ofn09ycjLjxo2r4GhFqEiiFiKEYmNjfZ43fSUmT54sLehqSn5MFEIIi5NELYQQFieJWgghLE4StRBCWJwkalElSJnTkooXiapo3kWlvJ0+fZpOnTqRnJzsKdhkBc2bN+fMmTOhDiMo5KwPIYKkKpU5LY/169eTkJDA3//+94Cf43K5sNvtQYyqepMWtahSamqZ0x07dtC1a1cSExPp2LFjicu7/ZUy/fe//01SUhJJSUkkJyd7nvfCCy+QmppKu3bteO655zzb+cMf/kCrVq24+eabOXjwYIk4du/ezW9+8xs++eQTkpKSuHTpEu+99x4JCQnEx8czdepUz7oxMTE8+eSTJCYm8sUXXxATE8OUKVO46aabuO2229i+fTvdu3cnLi6Of/7znyVey9cxBfy+XnUmLWpRPiGuc1oTy5zm5+czePBgli5dSmpqKufPny9R8c5fKdNZs2bx2muvkZaWRk5ODpGRkaxZs4bDhw+zfft2tNb069ePzZs3Ex0dzfvvv8/u3btxOp2kpKTQvn37Iq+TlJTEjBkzyMjI4NVXX+X7779n6tSp7Ny5k3r16tGzZ08+/vhjBgwYwIULF+jUqRMvvvgiABcuXODWW2/lhRdeYODAgfz2t79l7dq17N+/n5EjR9KvX78ir+XrmJb2etWZJGpRpZRW5nT06NEUFBQwYMAAkpKSipQ57du3Lz179ixS5rRQXl4ecLnM6X333ecpSRoI7zKnd955p99+Y39lTh977DHAf5nTgwcP0qRJE0/9Dl8FlbZu3co//vEPoGgp07S0NJ544gmGDRvG3XffTdOmTVmzZg1r1qzx1CrJycnh8OHDZGdnM3DgQE+Z1uKJ05cdO3bQvXt3GjZsCMCwYcPYvHkzAwYMwG63c88993jWDQ8Pp1evXoBRAjUiIoKwsDC/5VB9HdMNGzb4fb3qTBK1KB+L1jmtzmVOr8a0adPo27cvK1asIC0tjdWrV6O15umnny5xiXlFF/iPjIws0i8dFhbmuQN3IOVQfR3T4gWragrpoxZVSk0sc9q6dWtOnjzJjh07AKNaX/HE5q+U6dGjR0lISGDq1KmkpqaSmZnJHXfcwZtvvklOTg4AJ06c4NSpU3Tr1o2PP/6YS5cukZ2dzb/+9a8y4+/YsSP//ve/OXPmDC6Xi/fee49bbrkl4PdfGl/HNJivZ2XSohZVSk0scxoeHs7SpUuZOHEily5dIioqinXr1hVZx18p0zlz5rBx40ZsNhs33XQTvXv3JiIiggMHDtClSxfA+NHv7bffJiUlhcGDB5OYmMi1117rs5xqcU2aNOH555+nR48eaK3p27cv/fv3D/j9l2bTpk0ljmkwX8/KpMypKJOUOQ2eiixzKqoOKXMqRBVSkWVORfUliVqIEKrIMqei+pIfE4UQwuIkUQshhMVJohZCCIuTRC2EEBYniVpUCVLm1LdRo0bxwQcfBPU1vPXu3Zvjx49X2utdjTlz5nDx4sVQh1EhAk7USim7Uuo/SqlPgxmQENXF+PHjGTFiRKjDqDCXLl3i7NmzNG3aNNShBKRGJmrgMeBAsAIRIhA1tczpjBkzSE1NJT4+nrFjx+LrQrUVK1bQpk0b2rdvz6RJkzyx+iuB6q1v376e+cnJycyYMQOAZ599lgULFnjef/fu3QGjJnVycjIJCQmMHj3aU9jK25EjR7jttttITEwkJSWFo0eP+j1+Q4YM4bPPPvM81983BV/lWS9cuEDfvn1JTEwkPj6epUuX8vLLL/P999/To0cPevToUWI7VU1A51ErpZoCfYE/AE8ENSJhaYcPP05Ozu4K3WZMTBItW84JaN2aWOYUjH8Kzz77LADDhw/n008/5a677vIsz83NZdy4cWzevJkWLVowdOhQzzJ/JVC9paens2XLFm644QYcDgfbtm0DYMuWLcybNw+AlStXMmDAAHJzcxk1ahTr16+nVatWjBgxgtdff53HH3+8yDaHDRvGtGnTGDhwILm5ubjdbr/Hb/DgwSxbtoy+ffuSn5/P+vXref3114tsz1951tOnT3Pdddd5Ev25c+eoU6cOL730Ehs3bqRBgwalHr+qINAW9RzgN4Db3wpKqbFKqQylVMbp06crIjYhSiitzOnChQuZPn06e/fuJTY2tkiZ01WrVlG7du0iZU6TkpIYN24cJ0+eBC6XOV2wYAEulyvgmLzLnH744YeeMqHF+StzOmTIEMB/mVOAjRs30qlTJxISEtiwYQPffPNNkeWZmZnExcXRokULgCKJeuvWrQwfPhwoWgLVW3p6Ops3b2bbtm307duXnJwcLl68yLfffkvr1q0B2LZtm+eGAi1atKBVq1YAjBw5ks2bNxfZXnZ2NidOnGDgwIGAUUmvVq1afo9f79692bhxI3l5eaxcuZJu3bqVqLntXZ41JSWFzMxMDh8+TEJCAmvXrmXq1Kls2bKlWlbYK7NFrZS6Eziltd6plOrubz2t9XxgPhi1PioqQGEtgbZ8K1t1LnOam5vLhAkTyMjIoFmzZkyfPt3z2hUlNTWVjIwM4uLiuP322zlz5gwLFizw3Djg2LFjNGvWLGiXt0dGRtK9e3dWr17N0qVLPf+8vPkrzwqwa9cuVqxYwW9/+1t+9atfeb59VBeBtKjTgH5KqSzgfeBWpdTbQY1KCD9qYpnTwqTcoEEDcnJyfPbdtm7dmmPHjnla6oV9v4X7zFcJVG/h4eE0a9aM5cuX06VLF9LT05k1a5anr37lypWeov+tW7cmKyuLI0eOAPDWW2+VKDUaGxtL06ZN+fjjjwHj5gwXL170e/wABg8ezMKFC9myZYvntbz5K8/6/fffU6tWLe6//36mTJnCrl27PDEUv2VZVVVmi1pr/TTwNIDZon5Ka31/cMMSwreaWOa0bt26PPTQQ8THx9O4cWOf5UejoqKYO3cuvXr1Ijo6usg6/kqgFpeens769euJiooiPT2d48ePk56eDsCqVat45ZVXAKP1u3DhQgYNGoTT6SQ1NdXnjXzfeustxo0bx7PPPktYWBjLly/3e/wAevbsyfDhw+nfv7/PlnvPnj19lmc9cuQIU6ZMwWazERYW5unbHjt2LL169eK6665j48aNjBkzhvHjx9Ohg88CdZZWrjKnXom61HvUS5nT6kXKnAZPRZY5zcnJISYmBq01jzzyCC1btmTy5MlXHWNeXh5paWlSPKoCBbXMqdZ6E7DpSoMTQhRVkWVOFyxYwOLFi8nPzyc5OdlnX+6ViIiIkCQdYlLmVIgQqsgyp5MnT66QFrSwHrmEXAghLE4StRBCWJwkaiGEsDhJ1EIIYXGSqEWVIGVOA5eRkcGkSZMq/XWtrGvXrlf0vKysLN59992A1ouPj7+i1wiEnPUhRJD4ugikMnTo0KHCLupwuVzY7fYK2VYoOJ1OHA4Hn3/++RU9vzBR//rXv67gyMpHWtSiSqmpZU537NhB165dSUxMpGPHjmRnZ5Obm8sDDzxAQkICycnJbNy4sUSchVcldu/enbi4OF5++WXASEBt2rRh2LBh3Hjjjdx7772e2s3Nmzdn6tSppKSksHz5ctasWUOXLl1ISUlh0KBBnku4fb3nQPZh9+7duffeez2vX3jRnb/Sqc2bN+e5554jJSWFhIQEz/GaPn06w4cPp0uXLrRs2bJIOdb09HT69etH27ZtgcvfyPyVU83KyiI9PZ2UlBRSUlI8iX3atGls2bKFpKQkZs+ejcvlYsqUKZ5Sq3/7299KvMdu3boVqSVz8803l6usgC/Sohbl8viqx9n9v90Vus2kxknM6TUnoHVrYpnT/Px8Bg8ezNKlS0lNTeX8+fNERUXx17/+FaUUe/fuJTMzk549e3Lo0KESz8/MzGTjxo1kZ2fTunVrHn74YQAOHjzIG2+8QVpaGqNHj2bu3LmehFu/fn1PvZS7776bdevWER0dzZ///GdeeuklHnnkEZ/vOZB9+J///IdvvvmG6667jrS0NLZt20aHDh1KLZ3aoEEDdu3axdy5c5k1axZ///vfAfj666/58ssvuXDhAsnJyfTt2xcwijTt27fPU02wkL9yqlpr1q5dS2RkJIcPH2bo0KFkZGTw/PPPM2vWLD791Lhfyvz586lTpw47duzwXLHZs2dPlFKe13jwwQdZtGgRc+bM4dChQ+Tm5pYoR1Be0qIWVUpNLHN68OBBmjRp4qnfUbt2bRwOB1u3buX++42yO23atOGGG27wmaj79u1LREQEDRo04Nprr+WHH34AjNolaWlpANx///1s3brV85zBgwcD8OWXX7J//37S0tJISkpi8eLFfPfdd37fcyD7sGPHjjRt2hSbzUZSUhJZWVlllk71te8A+vfvT1RUFA0aNKBHjx5s377d8xrFkzTgt5xqQUEBDz30EAkJCQwaNIj9+/f7jH3NmjUsWbKEpKQkOnXqxNmzZzl8+HCRdQYNGsSnn35KQUEBb775JqNGjfK5rfKQFrUol0BbvpWtOpc5vVqFr1v8tb1bgcWno6OjAaOr6fbbb+e9994rsV1f77msfVhaPIG8h+Lr+3sPhfEX56+c6uzZs2nUqBF79uzB7XYTGRnp8/laa1555RXuuOOOIvO9/3nUqlWL22+/nU8++YRly5axc+fOMt9fWaRFLaqUmljmtHXr1pw8eZIdO3YARrU+p9NZpHzpoUOH+O9//+sp8h+I//73v3zxxRcAvPvuu9x8880l1uncuTPbtm3zlDS9cOEChw4d8vuey9qH/gRSOtWXTz75hNzcXM6ePcumTZt8VhYszlc51XPnztGkSRNsNhtvvfWW59tA8VKpd9xxB6+//joFBQWAsd8vXLhQ4jXGjBnDpEmTSE1NpV69emXvgDJIi1pUKTWxzGl4eDhLly5l4sSJXLp0iaioKNatW8eECRN4+OGHSUhIwOFwsGjRoiKt1bK0bt2a1157jdGjR9O2bVtP37W3hg0bsmjRIoYOHer5cW/mzJnExsb6fM9l7UN/Ai2dWly7du3o0aMHZ86c4Xe/+x3XXXedz+4fb77KqU6YMIF77rmHJUuWeErFFm7fbreTmJjIqFGjeOyxx8jKyiIlJQWtNQ0bNvTU3PbWvn17ateuzQMPPBDQ+y9LucqcBkrKnFYvUuY0eCqyzGl5ZGVlceedd3p+aK2Kpk+fTkxMjOcHUCv5/vvv6d69O5mZmdhsJTsuglrmVAhRsSqyzKmwhiVLlvDMM8/w0ksv+UzSV0Ja1KJM0qIWomKVt0UtPyaKgATjH7oQNdGV/C1JohZlioyM5OzZs5KshbhKWmvOnj3r9/Q/f6SPWpSpadOmHD9+nNOnT4c6FCGqvMjISJo2bVqu50iiFmUKCwvzeZWXEKJySNeHEEJYnCRqIYSwOEnUQghhcZKohRDC4iRRCyGExUmiFkIIi5NELYQQFieJWgghLE4StRBCWJwkaiGEsDhJ1EIIYXGSqIUQwuIkUQshhMVJohZCCIsrM1ErpSKVUtuVUnuUUt8opX5fGYEJIYQwBFKPOg+4VWudo5QKA7YqpVZqrb8McmxCCCEIoEWtDTnmZJg5BOWeTFu2wKlTwdiyEEJUXQH1USul7Eqp3cApYK3W+isf64xVSmUopTKu5JZNP/4IffrAsGHgcpX76UIIUW0FlKi11i6tdRLQFOiolIr3sc58rXUHrXWHhg0bljuQa66B2bNh3TqYObPcTxdCiGqrXGd9aK1/BjYCvYIRzIMPwvDh8Pvfw9q1wXgFIYSoegI566OhUqquOR4F3A5kBiMYpeD116FtW6ML5MSJYLyKEEJULYG0qJsAG5VSXwM7MPqoPw1WQNHRsHw5XLwIQ4ZAQUGwXkkIIaqGQM76+Fprnay1bqe1jtdazwh2UDfeCPPnw9at8MwzwX41IYSwNstemfjrX8P48fDCC/DPf4Y6GiGECB3LJmowzgJJSYGRI+Hbb0MdjRBChIalE3VkpNFfrTXcdx/k5YU6IiGEqHyWTtQAcXGwcCFkZMCTT4Y6GiGEqHyWT9QAAwfCE0/Aa6/B0qWhjkYIISpXlUjUAM8/D126wJgxcPBgqKMRQojKU2USdViY0ZqOiIBBg4zzrIUQoiaoMokaoFkzePtt2LcPHn001NEIIUTlqFKJGqBXL+MimIULjUEIIaq7KpeoAaZPhx494JFHYO/eUEcjhBDBVSUTtd0O774LderAvfdCdnaoIxJCiOCpkokaoHFjeP99OHIEHnrIuChGCCGqoyqbqAFuucW4ycDSpUZ5VCGEqI6qdKIGmDrVuIXX5MnG1YtCCFHdVPlEbbPBkiVGV8igQfDTT6GOSAghKlaVT9QA9evDsmXGHWFGjZL+aiFE9VItEjVAp04wa5ZRu/rFF0MdjRBCVJxqk6gBJk6Ee+6BadOMu8MIIUR1UK0StVLwxhvQogUMHgynT4c6IiGEuHrVKlGDcRHM8uVw9qxxJ3OXK9QRCSHE1al2iRogKQlefRXWroU//CHU0QghxNWploka4MEHYfhwoy7IunWhjkYIIa5ctU3UShlXK954o3FH8xMnQh2REEJcmWqbqAGio+GDD4ybDAwZAk5nqCMSQojyq9aJGowW9fz5xul6zzwT6miEEKL8qn2iBqPrY/x4+Mtf4F//CnU0QghRPjUiUQPMng0pKTByJGRlhToaIYQIXI1J1JGRxvnVbjfcdx/k5YU6IiGECEyNSdQAcXHGfRZ37ICnngp1NEIIEZgalagBBg6EJ54wLohZtizU0QghRNlqXKIGeP556NIFxoyBQ4dCHY0QQpSuRibqsDDj9l3h4cbNcS9dCnVEQgjhX41M1ADNmsHbb8O+ffDoo6GORggh/KuxiRqgVy/jIpg334RFi0IdjRBC+FajEzUYRZt69IAJE2Dv3lBHI4QQJZWZqJVSzZRSG5VS+5VS3yilHquMwCqL3Q7vvmvUsR40CLKzQx2REEIUFUiL2gk8qbVuC3QGHlFKtQ1uWJWrcWN4/304fBjGjpWb4wohrKXMRK21Pqm13mWOZwMHgOuDHVhlu+UWmDnTSNjz5oU6GiGEuKxcfdRKqeZAMvCVj2VjlVIZSqmM01X0ZoVTp0KfPvD447B6daijEUIIQ8CJWikVA/wDeFxrfb74cq31fK11B611h4YNG1ZkjJXGZoMlS6BVK+jdG/74R6M2iBBChFJAiVopFYaRpN/RWn8Y3JBCq359+PJLGDrUOHVvwAD4+edQRyWEqMkCOetDAW8AB7TWLwU/pNCLjjYuhnn5ZVi5Ejp0gK+/DnVUQoiaKpAWdRowHLhVKbXbHPoEOa6QUwomToRNm4xbeXXubCRvIYSobI6yVtBabwVUJcRiSWlpsGsXDB5s3NX8q6/gxReNOiFCCFEZavyViYFo3BjWrYMnnzTKo3bvLnc1F0JUHknUAQoLg1mzjBrWX39t3NZr06ZQRyWEqAkkUZfToEHGHWKuuQZuu83oBpErGYUQwSSJ+grceCNs327cLeapp4x7MEqNECFEsEiivkKxsUY3yKxZ8NFH0LEjHDgQ6qiEENWRJOqroJTxA+O6dfDjj0ayXr481FEJIaobSdQVoHt34xS+hASjG+Spp8DpDHVUQojqQhJ1Bbn+euMskIkTjR8Yb7sN/ve/UEclhKgOJFFXoPBw47Lzt982fmxMSYFt20IdlRCiqpNEHQTDhhmFnaKjjW6RV16RU/iEEFdOEnWQtGtnnG/dpw9MmgT33w8XLoQ6KiFEVSSJOojq1jVO3fvjH407x3TubNzuSwghykMSdZDZbPD007BqFZw8aZRM/eSTUEclhKhKJFFXkttvN07ha9XKuBnB//t/4HKFOiohRFUgiboS/eIXsGWLcafzP/0JevWCKnp7SSFEJZJEXckiI+Fvf4M33zSSdvv2xql8QgjhjyTqEHngAfj8c7DbIT3dSN5yCp8QwhdJ1CGUkgIZGXDrrTB+PIweDZcuhToqIYTVSKIOsfr14dNP4bnnYNEi6NoVjh0LdVRCCCuRRG0BdjtMn24k7Kws4xS+FStCHZUQwiokUVtI376wc6dxdsidd8LvfgenToU6KiFEqEmitpi4OPjiCxgxAmbONG6s27Gj0TXy5Zdy7rUQNZEkaguKioKFC40LZGbMMG6sO3MmdOkCjRoZRZ/eflvOwRaiplA6COeEdejQQWdkZFT4dmuyH3+ENWtg5UpjOH3auMNMair07m0Uf+rQwbhkXQhR9SildmqtO/hcJom66nG7jdb2ypXGj45ffWWcg92ggXG1Y+/e0LOnMS2EqBokUVdzZ85cbm2vWmVMK2X0bffpYyTu9u2ltS2ElUmirkHcbuMimsIuku3bjdZ2w4ZFW9v164c6UiGEN0nUNdjp00Zre8UKWL0azp41WtadOhlJu3dv4wpJaW0LEVqSqAVgnNqXkWEk7ZUrjTvQAFx7rdHa7tPHaG3XqxfaOIWoiSRRC59OnTJa2StXGo8//mi0rDt3vty3nZQkrW0hKoMkalEml8vozy5sbe/cacxv1AhuuQWaNjUuvmnc2JhXOF6/vnEJvBDi6lSZRH38+Ms4HNcQFdWCyMgWhIc3RilpzoXCDz8YZ5AU/iD5v//5ruxntxtdJ97J21dCb9wY6tQxzkYRQpRUJRK11i42b66F1vmeeUpFEBnZ3JO4C4fCaYejHkr+8iuF1pCTYyTsH34wHr2H4vOczpLbiIgILKE3agTR0ZX/HoUIpdIStaOyg/FHKTs333yOvLzvuHTpW3JzLw+XLh3j/PmvcDp/KvIcu712kcRdPJHb7bVC9G6qH6UgNtYYWrYsfV23G376qfSEnpVl1C45fdr3DRNiYkom9AYNoHbt0ofYWOlTF9VPmS1qpdSbwJ3AKa11fCAbDVYftdN5zkcSvzzudhf9bh4W1shvEo+IaIbNFlbhMYrycTqNC3RKa50Xzvvpp7K3B0ayLiuhFw516vhP+A7LNGNETXBVXR9KqW5ADrAk1Im6NFprCgpOeSXuY8WS+n8B79JzNiIimvlJ5M1xOK7BZouUrhULcbkgOxvOny97OHfO/7Ls7MBue1arlu/EXquWUTgrMrJ8j/6WyTcAAVfZ9aG13qyUal7hUVUwpRTh4Y0ID29EnTqdSyx3u53k5R332Rr/8cdV5Oef9LFVO3Z7DHZ7DA5HrDkeaw4xnkdjWdF5dntssecY25EfR6+c3Q516xrD1XC74cKFwJJ68eHwYbh40fhhNTf38uPVCA8vf9KPjDSqKtrtRQeH48rnXenzC9syShUdL21eedcva55Sl2Oqjm2rCvtyp5QaC4wF+MUvflFRm60wNpuDqKjmREU1B3qUWO5yXSI39zsziWfhdJ7D5crB5co2hxzPY27ud0WWFe9yKT2OWn6S+OVkX7jMZos2E7sCFEoptAa3BpfWuNG4tcbp1ri0RqNxucGp3bi1scylNU6327OuZ9pcx3u5y23MM57vxqWNeRqw2+zYlR2HzYFd2Y1pc9xhc3iW25UDh92BXRnzHDa7Oe7AYQvzrBdmD8OmHOZzHea8cHPbxjzjfdvMbzWFgwY0xjdB7XcaKHUdm01Tp44xNGumweWEgnx0fj7k50FBPuSb005jnII8KDB/JXU4wGFkLG13UKAdFLgd5Okw8l0O8lwO8t3GY57LzqUCO9n5TnLy8snOzSMnL5ecvDwuFeRxIT+XS848LhbkkuvM45IzjzxXLrnuPM65c8l355GvcykgjwLycLpycV7MQ2uFdjnAbQftQLkdaLc57XZ4DWGeecb6YcajdqBdYcY6rjC0KwxduMwd5lnmdoV5lhvbMrer7Z7nFn0t73nFp73ioayMqrHjwoGzyBBGQYl5dlyeKW1zoMKM44LDgTKPkwpzeB4dYco4hMWGsLCS8wJdHhZmfOuaPDngdBCwCkvUWuv5wHwwuj6uZBtjJjQlTzvNv0nzD9NmPhbO8/wr9TevtHVtRbetfKyPQiuMxFZscOH2mnbg0nVwU9tYply4cJmPblzKjRu3MQ83bs+0xsU53PyM22t7hYlXo3FjJOPCR5f2eryqo1S12JVRMN1ufgwKHwvnFZ9fuH7huL/n232sW+TR6zm2YtuxK3BqyHNDnst4zHVDvst8dEOuy3z0WiffXfjvoxRh5uDFBkTYIcJmDLXM8XDzi1nh56L44MbHPK/PkdMCd7wv3M8Or0eHuf8d5nLvac888zGscFobj8p8T8r8f6zMcc+013KljeOhtAJt/sMoMm4DDS5tw6lBY0xrbQOt0FqBS6FdNvQlY1prGxHHazGZrArfV5b6ueTL2HNcUk7zE23uVX/jxafdpT3HHPE57ptNg10bj96D3V1s2ms83M86vrZV2jpKm/2WNvND6LXM+FDbsKOwKRsOc9yubMa0zYZd2bHZjHkOZcdms2FXymy52rDbbcajzXa5JWyzY7PbL8+z2bDbjfnKpnC5XTjdTlxuFy7tNMa1y5x24dQuXNptzNMunNr8J2W2zgtwG8vNRzduCrTGrcx/XtqNE43L+PzjUuC2gRNw2YxppzITkPnoVOC22XDaFG6lcNkULpvNeL5N4Sqcp5Rnm3kKY13ApbT5iPkPFJyef8raiKfwWwtuz7cWG4ooexhRKowom4NIm4NI5aCWclAbO1HKTqTNTi2bnUi7jShsRGobtdw2IrUiyg2RbkUttyLSpYlyKaLcmiinJtIFUU43UQWaKKebMKcb5XIZv7oWPjpdxjeAwrxiA6305WnPfH15+vIXM3OexmUz9neBuX8LlBuXzZh2Kygwlztt4FTacwxcNk2B17TTpiiwGfvaaQenUhTYjMfC7XnWVcYxLVDGL0YF5nFxoo1jDRR4HQsn4NSFx6JwHC5p8xhpbf7jKfyD1oXfp7zSgPb+nlU0LYDZNLo8r/gjlPxNo8S65ki9IF38ZalEve/P2ZX/olobg8tldF663RVzv6uKOD9d68sdbw6Hkb2rYwect8JjUSQxmYNSxsnY4eHGEIJLIt3ajTK7oUT1prUbrd2AC60vD+D2GneZ6xnjZXfnXJkyE7VS6j2gO9BAKXUceE5r/UZQogmFwi4P+endGgp/FbLouXE2+TG4xlDKZv5GFPrPYiBnfQytjECEEEL4Js0DIYSwOEnUQghhcZKohRDC4iRRCyGExUmiFkIIi5NELYQQFieJWgghLE4StRBCWJwkaiGEsDhJ1EIIYXGSqIUQwuIkUQshhMVJohZCCIuTRC2EEBYniVoIISxOErUQQlicJGohhLA4SdRCCGFxkqiFEMLiJFELIYTFSaIWQgiLk0QthBAWJ4laCCEsThK1EEJYnCRqIYSwOEnUQghhcZKohRDC4iRRCyGExUmiFkIIi5NELYQQFieJWgghLE4StRBCWJwkaiGEsDhJ1EIIYXGSqIUQwuICStRKqV5KqYNKqSNKqWnBDkoIIcRlZSZqpZQdeA3oDbQFhiql2gY7MCGEEIZAWtQdgSNa62Na63zgfaB/cMMSQghRyBHAOtcD/+c1fRzoVHwlpdRYYKw5maOUOniFMTUAzlzhcyuTxFnxqkqsEmfFqipxQnBjvcHfgkASdUC01vOB+Ve7HaVUhta6QwWEFFQSZ8WrKrFKnBWrqsQJoYs1kK6PE0Azr+mm5jwhhBCVIJBEvQNoqZRqoZQKB4YA/wxuWEIIIQqV2fWhtXYqpR4FVgN24E2t9TdBjOmqu08qicRZ8apKrBJnxaoqcUKIYlVa61C8rhBCiADJlYlCCGFxkqiFEMLiKj1RK6WylFJ7lVK7lVIZ5rxrlFJrlVKHzcd65nyllHrZvHT9a6VUSiXF2NqMr3A4r5R6XCk1XSl1wmt+H6/nPG3GeVApdUeQ43tTKXVKKbXPa16596FSaqS5/mGl1MhKivMFpVSmGctHSqm65vzmSqlLXvt2ntdz2pufmSPme1GVEGe5j3VllFrwE+tSrzizlFK7zfmh3KfNlFIblVL7lVLfKKUeM+db6nNaSpzW+pxqrSt1ALKABsXm/QWYZo5PA/5sjvcBVgIK6Ax8FYJ47cD/ME5Gnw485WOdtsAeIAJoARwF7EGMqRuQAuy70n0IXAMcMx/rmeP1KiHOnoDDHP+zV5zNvdcrtp3tZuzKfC+9KyHOch1rczgKxAHh5jptK+PYF1v+IvCsBfZpEyDFHI8FDpn7zlKf01LitNTn1CpdH/2Bxeb4YmCA1/wl2vAlUFcp1aSSY/sVcFRr/V0p6/QH3tda52mtvwWOYFx6HxRa683Ajz5iKM8+vANYq7X+UWv9E7AW6BXsOLXWa7TWTnPyS4zz8v0yY62ttf5SG38NS7j83oIWZyn8HetKKbVQWqxmC+4+4L3StlFJ+/Sk1nqXOZ4NHMC4ytlSn1N/cVrtcxqKRK2BNUqpncq47Bygkdb6pDn+P6CROe7r8vXrKydMjyEU/eA/an4derPwaxvWiLO8+9AKMY/GaHkUaqGU+o9S6t9KqXRz3vVmbIUqM87yHGsr7M904Aet9WGveSHfp0qp5kAy8BUW/pwWi9NbyD+noUjUN2utUzCq8T2ilOrmvdD8b2SJcwaVcYFPP2C5Oet14JdAEnAS42um5VhpH/qjlHoGcALvmLNOAr/QWicDTwDvKqVqhyo+qsixLmYoRRsVId+nSqkY4B/A41rr897LrPQ59RenVT6nlZ6otdYnzMdTwEcYXxl/KOzSMB9PmauH+vL13sAurfUPAFrrH7TWLq21G1jA5e6NUMcJ5d+HIYtZKTUKuBMYZv6xYnYlnDXHd2L097YyY/L+2lkpcV7BsQ7pZ0Ap5QDuBpYWzgv1PlVKhWEkv3e01h+asy33OfUTp6U+p5WaqJVS0Uqp2MJxjA77fRiXpBf+mjsS+MQc/ycwwvxFuDNwzutrU2Uo0kIp1j8+ECN2MOIcopSKUEq1AFpi/LBQmcq7D1cDPZVS9cyv9T3NeUGllOoF/Abop7W+6DW/oTJqn6OUisPYh8fMWM8rpTqbfbAjvN5bMOMs77EOdamF24BMrbXn63co96m53TeAA1rrl7wWWepz6i9Oy31OK+pXyUAGjF/E95jDN8Az5vz6wHrgMLAOuMacrzBuWnAU2At0qMRYo4GzQB2veW+ZcXyN8cFq4rXsGTPOg1TwL+g+YnsP4ytYAUZf2INXsg8x+t6OmMMDlRTnEYw+x93mMM9c9x7zM7Eb2AXc5bWdDhiJ8ijwKuYVtUGOs9zHGuPMhUPmsmcq69ib8xcB44utG8p9ejNGt8bXXse6j9U+p6XEaanPqVxCLoQQFmeV0/OEEEL4IYlaCCEsThK1EEJYnCRqIYSwOEnUQghhcZKohRDC4iRRCyGExf1/exCXUESbDe4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_values = range(500,2500,200)#[500,1000,1500,2000,4000]#,6000,8000,10000]\n",
    "d = 5\n",
    "iters = 30\n",
    "total_privacy_budget=0.5\n",
    "\n",
    "losses(n_values, d, iters, total_privacy_budget, pop_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-google",
   "metadata": {},
   "source": [
    "- dist between X.T@X and identity (Frobenius norm)\n",
    "- dist between coinpress_cov and identity (also F norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "described-organizer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11137338082960183\n",
      "0.1626050815322836\n"
     ]
    }
   ],
   "source": [
    "d = 5\n",
    "n = 2000\n",
    "\n",
    "X = np.random.normal(0, 1.0, (n, d))\n",
    "X = np.array(X)\n",
    "\n",
    "errors = []\n",
    "cov_errors = []\n",
    "for i in range(100):\n",
    "    errors.append(np.linalg.norm(((1/n)*X.T@X - np.eye(d)), 'fro'))\n",
    "    cov_errors.append(np.linalg.norm((coinpress_linalg_covariance(X, d, t=2, total_budget=0.5) - (1/n)*X.T@X), 'fro'))\n",
    "    \n",
    "print(np.mean(np.array(errors)))\n",
    "print(np.mean(np.array(cov_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silent-croatia",
   "metadata": {},
   "source": [
    "PLOTS\n",
    "- pop_loss, l2_error\n",
    "- clip values before taking average? or find median\n",
    "    - general principle when looking at large avg errors: are all errors abt the same or is there something skewing avg\n",
    "    \n",
    "OTHER\n",
    "- 'hyperparameter tuning' figure out privacy split\n",
    "- norm of beta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
