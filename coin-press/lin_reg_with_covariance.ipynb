{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import algos\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closed form solution: beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "Consider the scenario where:\n",
    "- $x$ ~ $N(0, I_{dxd})$\n",
    "- $y|x$ ~ $N(\\langle x,\\beta \\rangle, \\sigma^2)$\n",
    "- We NOW DO NOT know $\\frac{1}{n}X^TX = I_{dxd}$\n",
    "- Need to estimate $ \\frac{1}{n}X^Ty \\approx E(x * \\langle x, \\beta \\rangle) $\n",
    "- Use CoinPress with input $z_i = x_iy_i$\n",
    "- AND need to estimate $ (\\frac{1}{n}X^TX)^{-1} \\approx (\\frac{1}{n}Cov(X))^{-1} $\n",
    "- Use CoinPress with input $x_i$\n",
    "\n",
    "\n",
    "But another thing we need to consider is that CoinPress assumes covariance matrix of z is $I_{dxd}$\n",
    "- Can we assume this? No...\n",
    "- Therefore we must normalize the $z_i$'s that we pass to CoinPress\n",
    "- We have calculated the diagonals of $cov(Z)$ are $\\beta_j^2  + ||\\beta||_2^2 + 1$ \n",
    "- Since as of right now, $\\beta$ ~ $N(0,1)$, $\\beta_j^2 = 1$, $||\\beta||_2^2 = d$, so each diagonal entry is approx $d+2$\n",
    "- Therefore, if the diagonals are >> the non-diagonals, we can assume that $\\frac{z}{\\sqrt{d}}$ ~ $N(C, I_{dxd})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n,d):\n",
    "    \n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "    \n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = random.normal(0,1.0,(n,d))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # underlying distribution (beta hat)\n",
    "    underlying_dist = random.normal(0,1.0,(1,d))\n",
    "    underlying_dist = np.array(underlying_dist)\n",
    "    \n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "    \n",
    "    return X,y,z,underlying_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_matrix(z):\n",
    "    z = z - underlying_dist\n",
    "    return (z.T@z)/n  # z.t@z grows w n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_covariance():\n",
    "    predicted_cov = np.zeros((d,d))\n",
    "    for row in range(d):\n",
    "        for col in range(d):\n",
    "            if row == col:\n",
    "                predicted_cov[row][col] = underlying_dist[0][row]**2 + np.linalg.norm(underlying_dist[0]) ** 2 + 1 \n",
    "            else:\n",
    "                predicted_cov[row][col] = underlying_dist[0][row]*underlying_dist[0][col]\n",
    "                \n",
    "    return predicted_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linreg_mean(z, c, r, d, beta_norm_sqr=None, t=2, total_budget=0.5):\n",
    "    if beta_norm_sqr is None: \n",
    "        beta_norm_sqr = d\n",
    "    z = z/np.sqrt(2*beta_norm_sqr+1)\n",
    "    rho = [(1.0/4.0)*total_budget, (3.0/4.0)*total_budget]\n",
    "    return algos.multivariate_mean_iterative(z, c, r, t, rho)*np.sqrt(2*beta_norm_sqr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linalg_covariance(x, d, t=2, total_budget=0.5):\n",
    "    '''need X and args={d, u, rho, t}'''\n",
    "    x = torch.FloatTensor(x)\n",
    "    class Args:\n",
    "        def __init__(self, n, d, u, rho, t):\n",
    "            self.n = n\n",
    "            self.d = d\n",
    "            self.u = u\n",
    "            self.rho = rho\n",
    "            self.t = t\n",
    "    n = len(x)\n",
    "    rho = [(1.0/4.0)*total_budget, (3.0/4.0)*total_budget]\n",
    "    u = 10 * np.sqrt(d)\n",
    "    args = Args(n, d, u, rho, t)\n",
    "    return algos.cov_est(x, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.403831  ,  1.3659672 ,  2.0771546 , ..., -1.1708544 ,\n",
       "        -0.5282894 ,  1.9744301 ],\n",
       "       [ 1.365955  , 15.840675  , -1.3151397 , ...,  1.5317687 ,\n",
       "        -0.77592933,  3.6487315 ],\n",
       "       [ 2.0771556 , -1.3151358 , 23.579144  , ..., -2.1468685 ,\n",
       "         2.1946502 , -1.3288009 ],\n",
       "       ...,\n",
       "       [-1.1708528 ,  1.5317731 , -2.1468625 , ..., 26.349161  ,\n",
       "         0.5487872 , -1.9835037 ],\n",
       "       [-0.5282922 , -0.77592653,  2.1946492 , ...,  0.54877245,\n",
       "        25.765282  , -1.9798689 ],\n",
       "       [ 1.9744351 ,  3.648742  , -1.3287938 , ..., -1.9835054 ,\n",
       "        -1.9798774 , 21.833055  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.normal(0,1.0,(2000,50))\n",
    "x = torch.FloatTensor(x)\n",
    "np.array(coinpress_linalg_covariance(x, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(z,c,r,d,iters):\n",
    "    errors = []\n",
    "    for i in range(iters):\n",
    "        error = np.linalg.norm(np.mean(z, axis=0) - coinpress_linreg_mean(z, c, r, d))\n",
    "        errors.append(error)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze how well this algorithm works, we can find it's excess loss:\n",
    "$$\\mathbb{E}[(\\langle x, \\hat{\\beta} \\rangle - y)^2 - (\\langle x, \\beta \\rangle - y)^2]$$\n",
    "Because what we really care about is how well our estimate for $\\hat{\\beta}$ predicts the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excess_loss(beta_hat, beta, d):\n",
    "    \"\"\" generate n d-dimensional x values and y values to test excess loss of our predicted beta_hat vs. underlying distribution beta \"\"\"\n",
    "    \n",
    "    n = 1000\n",
    "    x = random.normal(0,1.0,(n,d))\n",
    "    x = np.array(x)\n",
    "    y = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        y.append(np.dot(beta, x[i]) + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    sum_losses = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        predicted_dist = (x[i] @ beta_hat - y[i])**2\n",
    "        actual_dist = (x[i] @ beta - y[i])**2 # if this = 1, it's essentially the same thing as n -> \\inf\n",
    "        loss = predicted_dist - actual_dist\n",
    "        sum_losses += loss\n",
    "    return sum_losses / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonprivate_linreg_mean(x, y):\n",
    "    \"\"\" find beta_hat from distribution \"\"\"\n",
    "    \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    n = len(y)\n",
    "    # Train the model using the training sets\n",
    "#     regr.fit(x, y)\n",
    "#     return (x.T @ y) / n\n",
    "    return np.linalg.inv(x.T @ x) @ x.T @ y\n",
    "#     return regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to: what if we did not add privacy - default solution to lin reg.\n",
    "- given data, what is solution, compare excess loss (use scipy linreg / closed form)\n",
    "- get a sense of what is a 'normal' excess risk\n",
    "- still wouldn't be zero, would help to have a sense of checking our baseline\n",
    "- As n goes to infinity, should have excess risk going to 0.\n",
    "- saw comparing it to CoinPress high total_budget doesn't make too significant a diff\n",
    "\n",
    "If we evaluate on new data, optimal soln is underlying_dist, expected loss of optimal soln 1\n",
    "- better to evaluate on a new dataset (generate x same way, y using underlying_dist) !!!\n",
    "- in expectation, actual loss is 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messing around with other underlying distributions ($\\beta$)\n",
    "- Nothing about our assumptions relies on $\\beta$ ~ $N(0,1)$\n",
    "- Will first try out running experiment with $N(\\mu, \\sigma^2)$, varying $\\mu$ and $\\sigma$\n",
    "- Then, we will need to rescale each $z_i$ by $2 \\|\\beta\\|^{2}_2 + 1$\n",
    "- Moving forward, will need to estimate $\\|\\beta\\|^{2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_beta_normal(n,d,beta_mean,beta_var):\n",
    "    \n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "    \n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = random.normal(0,1.0,(n,d))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # underlying distribution (beta hat)\n",
    "    underlying_dist = random.normal(beta_mean,beta_var,(1,d))\n",
    "    underlying_dist = np.array(underlying_dist)\n",
    "    \n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "    \n",
    "    return X,y,z,underlying_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_beta_normal(d, beta_mean=0, beta_var=1, iters=30):\n",
    "    n_values = [2000, 4000, 6000, 8000, 10000]\n",
    "#     n_values = [4000, 6000, 8000, 10000]\n",
    "#     n_values = [100, 500, 1000, 5000]\n",
    "    c = [0]*d\n",
    "#     r = 10*np.sqrt(d)\n",
    "    r = 100*np.sqrt(d)\n",
    "    \n",
    "    # want to keep track and plot coinpress vs. non-private excess loss\n",
    "    losses = []\n",
    "    nonpriv_losses = []\n",
    "\n",
    "    for n in n_values:\n",
    "        \"\"\" for all n values, take the average of the loss after running the trial t times\"\"\"\n",
    "        curr_losses = []\n",
    "        curr_nonpriv_losses = []\n",
    "        for i in range(iters):\n",
    "            # generated data = nxd matrix x, nx1 vector y, nxd matrix z\n",
    "            # TODO: eventually change how to find beta_norm\n",
    "            x,y,z,underlying_dist = generate_data_beta_normal(n,d,beta_mean,beta_var)\n",
    "            beta_norm = np.linalg.norm(underlying_dist) ** 2\n",
    "            \n",
    "            # generate b_hat, and it's nonprivate counterpart by using coinpress and general linreg respectively\n",
    "            b_hat = coinpress_linreg_mean(z, c, r, d, beta_norm, total_budget=0.5)@np.linalg.inv(np.array(coinpress_linalg_covariance(x, d)))\n",
    "            nonpriv_b_hat = nonprivate_linreg_mean(x,y)\n",
    "\n",
    "            # find excess loss of b_hat and nonprivate b_hat\n",
    "            loss = excess_loss(b_hat, underlying_dist[0], d)\n",
    "            nonpriv_loss = excess_loss(nonpriv_b_hat, underlying_dist[0], d)\n",
    "            curr_nonpriv_losses.append(nonpriv_loss)\n",
    "            curr_losses.append(loss)\n",
    "        losses.append(np.mean(np.array(curr_losses)))\n",
    "        nonpriv_losses.append(np.mean(np.array(curr_nonpriv_losses)))\n",
    "\n",
    "    print(f\"losses: {losses}\")\n",
    "    print(f\"non-private losses: {nonpriv_losses}\")\n",
    "    plt.plot(n_values, losses, 'bo-')\n",
    "    plt.plot(n_values, nonpriv_losses, 'rx--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses: [0.03569198403180949, 0.00757813611005436, 0.004431184041310101, 0.0036087832754494427, 0.0029591119926617162]\n",
      "non-private losses: [0.0023515588971704045, 0.0012677412170793649, -0.00024490124995623405, 0.0011394386845674542, 0.00046195036966810204]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_beta_normal(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.02289041e+00  2.40722155e-02  7.07324762e-03  1.02482289e-02\n",
      "   1.26108368e-02]\n",
      " [ 2.40722155e-02  1.02762628e+00  1.82737773e-02  6.52412206e-04\n",
      "  -3.32618144e-02]\n",
      " [ 7.07324762e-03  1.82737773e-02  1.04587825e+00  4.70536647e-02\n",
      "   2.73775465e-02]\n",
      " [ 1.02482289e-02  6.52412206e-04  4.70536647e-02  1.00593284e+00\n",
      "  -1.25188724e-02]\n",
      " [ 1.26108368e-02 -3.32618144e-02  2.73775465e-02 -1.25188724e-02\n",
      "   1.01027231e+00]]\n",
      "tensor([[ 9.9062e-01,  3.7000e-02,  1.2926e-04, -5.4188e-02,  2.8390e-02],\n",
      "        [ 3.6999e-02,  1.0243e+00, -9.6644e-03,  5.6649e-03, -1.4044e-02],\n",
      "        [ 1.2901e-04, -9.6640e-03,  1.0231e+00,  8.4457e-02, -3.2292e-02],\n",
      "        [-5.4188e-02,  5.6648e-03,  8.4457e-02,  1.0537e+00, -6.1951e-02],\n",
      "        [ 2.8390e-02, -1.4043e-02, -3.2292e-02, -6.1951e-02,  9.9548e-01]])\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "# then compare coinpress cov est to actual cov\n",
    "x,y,z,underlying_dist = generate_data_beta_normal(2000,5,0,1)\n",
    "print((1/2000)*x.T@x)\n",
    "print(coinpress_linalg_covariance(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "x = [True, False, True]\n",
    "x = np.array(x)\n",
    "print(np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
