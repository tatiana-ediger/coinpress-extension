{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import algos\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closed form solution: beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "Consider the scenario where:\n",
    "- $x$ ~ $N(0, I_{dxd})$\n",
    "- $y|x$ ~ $N(\\langle x,\\beta \\rangle, \\sigma^2)$\n",
    "- We NOW DO NOT know $\\frac{1}{n}X^TX = I_{dxd}$\n",
    "- Need to estimate $ \\frac{1}{n}X^Ty \\approx E(x * \\langle x, \\beta \\rangle) $\n",
    "- Use CoinPress with input $z_i = x_iy_i$\n",
    "- AND need to estimate $ (\\frac{1}{n}X^TX)^{-1} \\approx (\\frac{1}{n}Cov(X))^{-1} $\n",
    "- Use CoinPress with input $x_i$\n",
    "\n",
    "\n",
    "But another thing we need to consider is that CoinPress assumes covariance matrix of z is $I_{dxd}$\n",
    "- Can we assume this? No...\n",
    "- Therefore we must normalize the $z_i$'s that we pass to CoinPress\n",
    "- We have calculated the diagonals of $cov(Z)$ are $\\beta_j^2  + ||\\beta||_2^2 + 1$ \n",
    "- Since as of right now, $\\beta$ ~ $N(0,1)$, $\\beta_j^2 = 1$, $||\\beta||_2^2 = d$, so each diagonal entry is approx $d+2$\n",
    "- Therefore, if the diagonals are >> the non-diagonals, we can assume that $\\frac{z}{\\sqrt{d}}$ ~ $N(C, I_{dxd})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n,d):\n",
    "    \n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "    \n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = random.normal(0,1.0,(n,d))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # underlying distribution (beta hat)\n",
    "    underlying_dist = random.normal(0,1.0,(1,d))\n",
    "    underlying_dist = np.array(underlying_dist)\n",
    "    \n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "    \n",
    "    return X,y,z,underlying_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_matrix(z):\n",
    "    z = z - underlying_dist\n",
    "    return (z.T@z)/n  # z.t@z grows w n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_covariance():\n",
    "    predicted_cov = np.zeros((d,d))\n",
    "    for row in range(d):\n",
    "        for col in range(d):\n",
    "            if row == col:\n",
    "                predicted_cov[row][col] = underlying_dist[0][row]**2 + np.linalg.norm(underlying_dist[0]) ** 2 + 1 \n",
    "            else:\n",
    "                predicted_cov[row][col] = underlying_dist[0][row]*underlying_dist[0][col]\n",
    "                \n",
    "    return predicted_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linreg_mean(z, c, r, d, beta_norm_sqr=None, t=2, total_budget=0.5):\n",
    "    if beta_norm_sqr is None: \n",
    "        beta_norm_sqr = d\n",
    "    z = z/np.sqrt(2*beta_norm_sqr+1)\n",
    "    rho = [(1.0/4.0)*total_budget, (3.0/4.0)*total_budget]\n",
    "    return algos.multivariate_mean_iterative(z, c, r, t, rho)*np.sqrt(2*beta_norm_sqr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linalg_covariance(x, d, t=2, total_budget=0.5):\n",
    "    '''need X and args={d, u, rho, t}'''\n",
    "    x = torch.FloatTensor(x)\n",
    "    class Args:\n",
    "        def __init__(self, n, d, u, rho, t):\n",
    "            self.n = n\n",
    "            self.d = d\n",
    "            self.u = u\n",
    "            self.rho = rho\n",
    "            self.t = t\n",
    "    n = len(x)\n",
    "    rho = [(1.0/4.0)*total_budget, (3.0/4.0)*total_budget]\n",
    "    u = 10 * np.sqrt(d)\n",
    "    args = Args(n, d, u, rho, t)\n",
    "    return algos.cov_est(x, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.3060152e+01,  1.5692803e+00,  1.3403560e+00, ...,\n",
       "         6.7986768e-01,  8.5977507e-01, -8.3026606e-01],\n",
       "       [ 1.5692675e+00,  2.3551132e+01,  1.5496090e-01, ...,\n",
       "        -3.2413507e-01,  4.3385893e-01, -3.6098607e+00],\n",
       "       [ 1.3403559e+00,  1.5496144e-01,  2.1948887e+01, ...,\n",
       "         5.7584703e-01,  5.0566047e-03,  3.3675139e+00],\n",
       "       ...,\n",
       "       [ 6.7986780e-01, -3.2413119e-01,  5.7583004e-01, ...,\n",
       "         1.9161959e+01,  4.2980996e-01, -1.9027680e+00],\n",
       "       [ 8.5976732e-01,  4.3386349e-01,  5.0611645e-03, ...,\n",
       "         4.2980433e-01,  1.9186974e+01, -1.6449754e+00],\n",
       "       [-8.3026123e-01, -3.6098728e+00,  3.3675175e+00, ...,\n",
       "        -1.9027680e+00, -1.6449850e+00,  2.3464291e+01]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.normal(0,1.0,(2000,50))\n",
    "x = torch.FloatTensor(x)\n",
    "np.array(coinpress_linalg_covariance(x, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(z,c,r,d,iters):\n",
    "    errors = []\n",
    "    for i in range(iters):\n",
    "        error = np.linalg.norm(np.mean(z, axis=0) - coinpress_linreg_mean(z, c, r, d))\n",
    "        errors.append(error)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze how well this algorithm works, we can find it's excess loss:\n",
    "$$\\mathbb{E}[(\\langle x, \\hat{\\beta} \\rangle - y)^2 - (\\langle x, \\beta \\rangle - y)^2]$$\n",
    "Because what we really care about is how well our estimate for $\\hat{\\beta}$ predicts the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excess_loss(beta_hat, beta, d):\n",
    "    \"\"\" generate n d-dimensional x values and y values to test excess loss of our predicted beta_hat vs. underlying distribution beta \"\"\"\n",
    "    \n",
    "    n = 1000\n",
    "    x = random.normal(0,1.0,(n,d))\n",
    "    x = np.array(x)\n",
    "    y = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        y.append(np.dot(beta, x[i]) + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    sum_losses = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        predicted_dist = (x[i] @ beta_hat - y[i])**2\n",
    "        actual_dist = (x[i] @ beta - y[i])**2 # if this = 1, it's essentially the same thing as n -> \\inf\n",
    "        loss = predicted_dist - actual_dist\n",
    "        sum_losses += loss\n",
    "    return sum_losses / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonprivate_linreg_mean(x, y):\n",
    "    \"\"\" find beta_hat from distribution \"\"\"\n",
    "    \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    n = len(y)\n",
    "    # Train the model using the training sets\n",
    "#     regr.fit(x, y)\n",
    "#     return (x.T @ y) / n\n",
    "    return np.linalg.inv(x.T @ x) @ x.T @ y\n",
    "#     return regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to: what if we did not add privacy - default solution to lin reg.\n",
    "- given data, what is solution, compare excess loss (use scipy linreg / closed form)\n",
    "- get a sense of what is a 'normal' excess risk\n",
    "- still wouldn't be zero, would help to have a sense of checking our baseline\n",
    "- As n goes to infinity, should have excess risk going to 0.\n",
    "- saw comparing it to CoinPress high total_budget doesn't make too significant a diff\n",
    "\n",
    "If we evaluate on new data, optimal soln is underlying_dist, expected loss of optimal soln 1\n",
    "- better to evaluate on a new dataset (generate x same way, y using underlying_dist) !!!\n",
    "- in expectation, actual loss is 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messing around with other underlying distributions ($\\beta$)\n",
    "- Nothing about our assumptions relies on $\\beta$ ~ $N(0,1)$\n",
    "- Will first try out running experiment with $N(\\mu, \\sigma^2)$, varying $\\mu$ and $\\sigma$\n",
    "- Then, we will need to rescale each $z_i$ by $2 \\|\\beta\\|^{2}_2 + 1$\n",
    "- Moving forward, will need to estimate $\\|\\beta\\|^{2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_beta_normal(n,d,beta_mean,beta_var):\n",
    "    \n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "    \n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = random.normal(0,1.0,(n,d))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # underlying distribution (beta hat)\n",
    "    underlying_dist = random.normal(beta_mean,beta_var,(1,d))\n",
    "    underlying_dist = np.array(underlying_dist)\n",
    "    \n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "    \n",
    "    return X,y,z,underlying_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_beta_normal(d, beta_mean=0, beta_var=1, iters=30):\n",
    "    n_values = [2000, 4000, 6000, 8000, 10000]\n",
    "#     n_values = [4000, 6000, 8000, 10000]\n",
    "#     n_values = [100, 500, 1000, 5000]\n",
    "    c = [0]*d\n",
    "#     r = 10*np.sqrt(d)\n",
    "    r = 100*np.sqrt(d)\n",
    "    \n",
    "    # want to keep track and plot coinpress vs. non-private excess loss\n",
    "    losses = []\n",
    "    nonpriv_losses = []\n",
    "\n",
    "    for n in n_values:\n",
    "        \"\"\" for all n values, take the average of the loss after running the trial t times\"\"\"\n",
    "        curr_losses = []\n",
    "        curr_nonpriv_losses = []\n",
    "        for i in range(iters):\n",
    "            # generated data = nxd matrix x, nx1 vector y, nxd matrix z\n",
    "            # TODO: eventually change how to find beta_norm\n",
    "            x,y,z,underlying_dist = generate_data_beta_normal(n,d,beta_mean,beta_var)\n",
    "            beta_norm = np.linalg.norm(underlying_dist) ** 2\n",
    "            \n",
    "            # generate b_hat, and it's nonprivate counterpart by using coinpress and general linreg respectively\n",
    "#             print(np.array(coinpress_linalg_covariance(x, d)))\n",
    "            b_hat = coinpress_linreg_mean(z, c, r, d, beta_norm, total_budget=0.5)\n",
    "#     @np.linalg.inv(np.array(coinpress_linalg_covariance(x, d)))\n",
    "            nonpriv_b_hat = nonprivate_linreg_mean(x,y)\n",
    "\n",
    "            # find excess loss of b_hat and nonprivate b_hat\n",
    "            loss = excess_loss(b_hat, underlying_dist[0], d)\n",
    "            nonpriv_loss = excess_loss(nonpriv_b_hat, underlying_dist[0], d)\n",
    "            curr_nonpriv_losses.append(nonpriv_loss)\n",
    "            curr_losses.append(loss)\n",
    "        losses.append(np.mean(np.array(curr_losses)))\n",
    "        nonpriv_losses.append(np.mean(np.array(curr_nonpriv_losses)))\n",
    "\n",
    "    print(f\"losses: {losses}\")\n",
    "    print(f\"non-private losses: {nonpriv_losses}\")\n",
    "    plt.plot(n_values, losses, 'bo-')\n",
    "    plt.plot(n_values, nonpriv_losses, 'rx--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses: [0.018951513573352487, 0.010294468075262563, 0.010209461141936492, 0.0046275563499806735, 0.005030049690319952]\n",
      "non-private losses: [0.00220163097994675, 0.0011133171324391562, 0.0012228871823453495, 0.000496638803588384, 0.0006846214438615444]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_beta_normal(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95782908  0.00345724 -0.01692206  0.00596493 -0.00466567]\n",
      " [ 0.00345724  1.01578059 -0.0203745   0.02555674 -0.00924317]\n",
      " [-0.01692206 -0.0203745   1.04038152 -0.02301154  0.04331269]\n",
      " [ 0.00596493  0.02555674 -0.02301154  1.01117219 -0.00167436]\n",
      " [-0.00466567 -0.00924317  0.04331269 -0.00167436  0.97086325]]\n",
      "tensor([[ 0.9306,  0.0184, -0.0596, -0.0179, -0.0328],\n",
      "        [ 0.0184,  1.0533,  0.0087,  0.0574, -0.0284],\n",
      "        [-0.0596,  0.0087,  1.0032, -0.0239, -0.0254],\n",
      "        [-0.0179,  0.0574, -0.0239,  1.0203,  0.0014],\n",
      "        [-0.0328, -0.0284, -0.0254,  0.0014,  0.9507]])\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "# then compare coinpress cov est to actual cov\n",
    "x,y,z,underlying_dist = generate_data_beta_normal(2000,5,0,1)\n",
    "print((1/2000)*x.T@x)\n",
    "print(coinpress_linalg_covariance(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "x = [True, False, True]\n",
    "x = np.array(x)\n",
    "print(np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
