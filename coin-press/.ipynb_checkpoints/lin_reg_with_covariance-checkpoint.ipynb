{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import algos\n",
    "import numpy as np\n",
    "import math\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Closed form solution: beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "Consider the scenario where:\n",
    "- $x$ ~ $N(0, I_{dxd})$\n",
    "- $y|x$ ~ $N(\\langle x,\\beta \\rangle, \\sigma^2)$\n",
    "- We NOW DO NOT know $\\frac{1}{n}X^TX = I_{dxd}$\n",
    "- Need to estimate $ \\frac{1}{n}X^Ty \\approx E(x * \\langle x, \\beta \\rangle) $\n",
    "- Use CoinPress with input $z_i = x_iy_i$\n",
    "- AND need to estimate $ (\\frac{1}{n}X^TX)^{-1} \\approx (\\frac{1}{n}Cov(X))^{-1} $\n",
    "- Use CoinPress with input $x_i$\n",
    "\n",
    "\n",
    "But another thing we need to consider is that CoinPress assumes covariance matrix of z is $I_{dxd}$\n",
    "- Can we assume this? No...\n",
    "- Therefore we must normalize the $z_i$'s that we pass to CoinPress\n",
    "- We have calculated the diagonals of $cov(Z)$ are $\\beta_j^2  + ||\\beta||_2^2 + 1$ \n",
    "- Since as of right now, $\\beta$ ~ $N(0,1)$, $\\beta_j^2 = 1$, $||\\beta||_2^2 = d$, so each diagonal entry is approx $d+2$\n",
    "- Therefore, if the diagonals are >> the non-diagonals, we can assume that $\\frac{z}{\\sqrt{d}}$ ~ $N(C, I_{dxd})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n,d):\n",
    "    \n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "    \n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = random.normal(0,1.0,(n,d))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # underlying distribution (beta hat)\n",
    "    underlying_dist = random.normal(0,1.0,(1,d))\n",
    "    underlying_dist = np.array(underlying_dist)\n",
    "    \n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "    \n",
    "    return X,y,z,underlying_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance_matrix(z):\n",
    "    z = z - underlying_dist\n",
    "    return (z.T@z)/n  # z.t@z grows w n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_covariance():\n",
    "    predicted_cov = np.zeros((d,d))\n",
    "    for row in range(d):\n",
    "        for col in range(d):\n",
    "            if row == col:\n",
    "                predicted_cov[row][col] = underlying_dist[0][row]**2 + np.linalg.norm(underlying_dist[0]) ** 2 + 1 \n",
    "            else:\n",
    "                predicted_cov[row][col] = underlying_dist[0][row]*underlying_dist[0][col]\n",
    "                \n",
    "    return predicted_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linreg_mean(z, c, r, d, beta_norm_sqr=None, t=2, total_budget=0.5):\n",
    "    if beta_norm_sqr is None: \n",
    "        beta_norm_sqr = d\n",
    "    z = z/np.sqrt(2*beta_norm_sqr+1)\n",
    "    rho = [(1.0/4.0)*total_budget, (3.0/4.0)*total_budget]\n",
    "    return algos.multivariate_mean_iterative(z, c, r, t, rho)*np.sqrt(2*beta_norm_sqr+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coinpress_linalg_covariance(x, d, t=2, total_budget=0.5):\n",
    "    '''need X and args={d, u, rho, t}'''\n",
    "    x = torch.FloatTensor(x)\n",
    "    class Args:\n",
    "        def __init__(self, n, d, u, rho, t):\n",
    "            self.n = n\n",
    "            self.d = d\n",
    "            self.u = u\n",
    "            self.rho = rho\n",
    "            self.t = t\n",
    "    n = len(x)\n",
    "    rho = [(1.0/4.0)*total_budget, (3.0/4.0)*total_budget]\n",
    "    u = 10 * np.sqrt(d)\n",
    "    args = Args(n, d, u, rho, t)\n",
    "    return algos.cov_est(x, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.799217  , -0.51495856, -1.7155758 , ...,  2.6212785 ,\n",
       "         3.3105955 , -0.61287767],\n",
       "       [-0.51494783, 16.817719  ,  1.1406784 , ...,  1.3984563 ,\n",
       "         1.3346977 ,  1.6014928 ],\n",
       "       [-1.71558   ,  1.1406593 , 25.939177  , ..., -5.564719  ,\n",
       "         1.3687905 ,  1.3666035 ],\n",
       "       ...,\n",
       "       [ 2.6212757 ,  1.3984506 , -5.5647244 , ..., 22.062933  ,\n",
       "        -0.99298406, -2.102111  ],\n",
       "       [ 3.3105953 ,  1.334703  ,  1.3687915 , ..., -0.99298006,\n",
       "        17.2648    , -0.8376521 ],\n",
       "       [-0.61287975,  1.6014972 ,  1.3666192 , ..., -2.1021135 ,\n",
       "        -0.8376528 , 17.34919   ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = random.normal(0,1.0,(2000,50))\n",
    "x = torch.FloatTensor(x)\n",
    "np.array(coinpress_linalg_covariance(x, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(z,c,r,d,iters):\n",
    "    errors = []\n",
    "    for i in range(iters):\n",
    "        error = np.linalg.norm(np.mean(z, axis=0) - coinpress_linreg_mean(z, c, r, d))\n",
    "        errors.append(error)\n",
    "        \n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze how well this algorithm works, we can find it's excess loss:\n",
    "$$\\mathbb{E}[(\\langle x, \\hat{\\beta} \\rangle - y)^2 - (\\langle x, \\beta \\rangle - y)^2]$$\n",
    "Because what we really care about is how well our estimate for $\\hat{\\beta}$ predicts the true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excess_loss(beta_hat, beta, d):\n",
    "    \"\"\" generate n d-dimensional x values and y values to test excess loss of our predicted beta_hat vs. underlying distribution beta \"\"\"\n",
    "    \n",
    "    n = 1000\n",
    "    x = random.normal(0,1.0,(n,d))\n",
    "    x = np.array(x)\n",
    "    y = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        y.append(np.dot(beta, x[i]) + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    sum_losses = 0\n",
    "    n = len(x)\n",
    "    for i in range(n):\n",
    "        predicted_dist = (x[i] @ beta_hat - y[i])**2\n",
    "        actual_dist = (x[i] @ beta - y[i])**2 # if this = 1, it's essentially the same thing as n -> \\inf\n",
    "        loss = predicted_dist - actual_dist\n",
    "        sum_losses += loss\n",
    "    return sum_losses / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonprivate_linreg_mean(x, y):\n",
    "    \"\"\" find beta_hat from distribution \"\"\"\n",
    "    \n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    n = len(y)\n",
    "    # Train the model using the training sets\n",
    "#     regr.fit(x, y)\n",
    "#     return (x.T @ y) / n\n",
    "    return np.linalg.inv(x.T @ x) @ x.T @ y\n",
    "#     return regr.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to: what if we did not add privacy - default solution to lin reg.\n",
    "- given data, what is solution, compare excess loss (use scipy linreg / closed form)\n",
    "- get a sense of what is a 'normal' excess risk\n",
    "- still wouldn't be zero, would help to have a sense of checking our baseline\n",
    "- As n goes to infinity, should have excess risk going to 0.\n",
    "- saw comparing it to CoinPress high total_budget doesn't make too significant a diff\n",
    "\n",
    "If we evaluate on new data, optimal soln is underlying_dist, expected loss of optimal soln 1\n",
    "- better to evaluate on a new dataset (generate x same way, y using underlying_dist) !!!\n",
    "- in expectation, actual loss is 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Messing around with other underlying distributions ($\\beta$)\n",
    "- Nothing about our assumptions relies on $\\beta$ ~ $N(0,1)$\n",
    "- Will first try out running experiment with $N(\\mu, \\sigma^2)$, varying $\\mu$ and $\\sigma$\n",
    "- Then, we will need to rescale each $z_i$ by $2 \\|\\beta\\|^{2}_2 + 1$\n",
    "- Moving forward, will need to estimate $\\|\\beta\\|^{2}_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_beta_normal(n,d,beta_mean,beta_var):\n",
    "    \n",
    "    \"\"\"Creates an nxd matrix X, a 1xd underlying_dist vector, nx1 y vector, and nxd z vector (where zi=xi*yi)\"\"\"\n",
    "    \n",
    "    # generate an n x d data matrix with N(0,1) entries- feature matrix\n",
    "    X = random.normal(0,1.0,(n,d))\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # underlying distribution (beta hat)\n",
    "    underlying_dist = random.normal(beta_mean,beta_var,(1,d))\n",
    "    underlying_dist = np.array(underlying_dist)\n",
    "    \n",
    "    # Generates a label vector from underlying distribution plus some noise\n",
    "    y = []\n",
    "    for i in range(n):\n",
    "        y.append(np.dot(underlying_dist, X[i])[0] + random.normal(0,1))\n",
    "    y = np.array(y)  \n",
    "    \n",
    "    # Generate z = xy\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        z.append(X[i] * y[i])\n",
    "    z = np.array(z)\n",
    "    \n",
    "    return X,y,z,underlying_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_beta_normal(d, beta_mean=0, beta_var=1, iters=30):\n",
    "    n_values = [2000, 4000, 6000, 8000, 10000]\n",
    "#     n_values = [4000, 6000, 8000, 10000]\n",
    "#     n_values = [100, 500, 1000, 5000]\n",
    "    c = [0]*d\n",
    "#     r = 10*np.sqrt(d)\n",
    "    r = 100*np.sqrt(d)\n",
    "    \n",
    "    # want to keep track and plot coinpress vs. non-private excess loss\n",
    "    losses = []\n",
    "    nonpriv_losses = []\n",
    "\n",
    "    for n in n_values:\n",
    "        \"\"\" for all n values, take the average of the loss after running the trial t times\"\"\"\n",
    "        curr_losses = []\n",
    "        curr_nonpriv_losses = []\n",
    "        for i in range(iters):\n",
    "            # generated data = nxd matrix x, nx1 vector y, nxd matrix z\n",
    "            # TODO: eventually change how to find beta_norm\n",
    "            x,y,z,underlying_dist = generate_data_beta_normal(n,d,beta_mean,beta_var)\n",
    "            beta_norm = np.linalg.norm(underlying_dist) ** 2\n",
    "            \n",
    "            # generate b_hat, and it's nonprivate counterpart by using coinpress and general linreg respectively\n",
    "            b_hat = coinpress_linreg_mean(z, c, r, d, beta_norm, total_budget=0.5)@np.linalg.inv(np.array(coinpress_linalg_covariance(x, d)))\n",
    "            nonpriv_b_hat = nonprivate_linreg_mean(x,y)\n",
    "\n",
    "            # find excess loss of b_hat and nonprivate b_hat\n",
    "            loss = excess_loss(b_hat, underlying_dist[0], d)\n",
    "            nonpriv_loss = excess_loss(nonpriv_b_hat, underlying_dist[0], d)\n",
    "            curr_nonpriv_losses.append(nonpriv_loss)\n",
    "            curr_losses.append(loss)\n",
    "        losses.append(np.mean(np.array(curr_losses)))\n",
    "        nonpriv_losses.append(np.mean(np.array(curr_nonpriv_losses)))\n",
    "\n",
    "    print(f\"losses: {losses}\")\n",
    "    print(f\"non-private losses: {nonpriv_losses}\")\n",
    "    plt.plot(n_values, losses, 'bo-')\n",
    "    plt.plot(n_values, nonpriv_losses, 'rx--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "losses: [2371.988953663152, 150.45711944080645, 37.60067152093098, 14.522134572243782, 3.507931304281846]\n",
      "non-private losses: [0.0027328127489514927, 0.0009133528656972295, 0.0007508147928494225, 0.00075400543903787, 0.0004980454863379629]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "run_experiment_beta_normal(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.98111041 -0.0201929  -0.0093684   0.00868507  0.01337219]\n",
      " [-0.0201929   0.98750913  0.00924636 -0.03086653  0.01546189]\n",
      " [-0.0093684   0.00924636  1.01323661  0.02071331  0.00359675]\n",
      " [ 0.00868507 -0.03086653  0.02071331  1.05216    -0.01812421]\n",
      " [ 0.01337219  0.01546189  0.00359675 -0.01812421  1.04681388]]\n",
      "tensor([[ 0.9300, -0.0050,  0.0286,  0.0032, -0.0453],\n",
      "        [-0.0050,  0.9687, -0.0103, -0.0018, -0.0249],\n",
      "        [ 0.0286, -0.0103,  1.0607,  0.0449,  0.0512],\n",
      "        [ 0.0032, -0.0018,  0.0449,  1.0922, -0.0435],\n",
      "        [-0.0453, -0.0249,  0.0512, -0.0435,  0.9808]])\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "# then compare coinpress cov est to actual cov\n",
    "x,y,z,underlying_dist = generate_data_beta_normal(2000,5,0,1)\n",
    "print((1/2000)*x.T@x)\n",
    "print(coinpress_linalg_covariance(x,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "x = [True, False, True]\n",
    "x = np.array(x)\n",
    "print(np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
